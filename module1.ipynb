{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the capital of france is paris\n",
    "\n",
    "prompt = \"the capital of the united states is not \"\n",
    "\n",
    "next_token = \" \"\n",
    "\n",
    "output = \"the capital of france is paris, \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"the capital <pad> <pad> <pad> <pad> \"\n",
    "hedef = \"capital of <pad> <pad> <pad> <pad> \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 12 # gpt-4o 128k, gemma-3-1b 32K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, [0, 61, 1, 61, 2, 61, 0, 61, 3, 61, 4, 58, 61, 5, 61, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(\"tokenizer.json\")\n",
    "\n",
    "ids = tokenizer.encode(prompt)\n",
    "\n",
    "len(ids), ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 1437, 5279, 529, 506, 26974, 5022, 563, 711, 236743]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, Gemma3ForCausalLM\n",
    "\n",
    "gemma_tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\")\n",
    "gemma_model = Gemma3ForCausalLM.from_pretrained(\"google/gemma-3-1b-it\")\n",
    "\n",
    "gemma_tokenizer.encode(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma3ForCausalLM(\n",
       "  (model): Gemma3TextModel(\n",
       "    (embed_tokens): Gemma3TextScaledWordEmbedding(262144, 1152, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-25): 26 x Gemma3DecoderLayer(\n",
       "        (self_attn): Gemma3Attention(\n",
       "          (q_proj): Linear(in_features=1152, out_features=1024, bias=False)\n",
       "          (k_proj): Linear(in_features=1152, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=1152, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=1024, out_features=1152, bias=False)\n",
       "          (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "          (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Gemma3MLP(\n",
       "          (gate_proj): Linear(in_features=1152, out_features=6912, bias=False)\n",
       "          (up_proj): Linear(in_features=1152, out_features=6912, bias=False)\n",
       "          (down_proj): Linear(in_features=6912, out_features=1152, bias=False)\n",
       "          (act_fn): GELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
       "    (rotary_emb): Gemma3RotaryEmbedding()\n",
       "    (rotary_emb_local): Gemma3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1152, out_features=262144, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "girdi = \"the letter capital of the united states is not\"\n",
    "cikti = \"letter capital of the united states is not london\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the capital of the united states is not london. the capital of france is paris, and berlin is the capital of germany. rome is in italy, \\n\\nmadrid is in spain, and lisbon is in portugal. the capital of the united kingdom is not paris, and the capital of the united states is not berlin. \\nalthough these places are often mentioned together, although these capitals are often mentioned together, although these are often mentioned together, \\neach country has its own capital, and each country has its own city, and each capital has its own identity, and each capital has its own history. washington \\nis the capital of the united states, and london is the capital of the united kingdom. paris is known for art and fashion, and berlin is known for art and \\nhistory, and rome is known for art and history, and madrid is known for culture and history, and lisbon is known for culture and art. rome is rich with culture, \\nrome is rich with history, rome is rich with art, and madrid is rich with art and culture. lisbon is a unique city in portugal with a rich history, a rich culture, \\nand a rich identity. these capitals are often mentioned together, these capitals are often mentioned together in art, these capitals are often mentioned together \\nin culture, these capitals are often mentioned together in history. the united states is not in europe, the united states is not in any european place, and \\nwashington is not in any european city. each european country is made of important capitals, and each european capital is made of art, history, and culture. \\nthe capital of the united states is washington, the capital of the united kingdom is london, the capital of france is paris, the capital of germany is berlin, \\nthe capital of italy is rome, the capital of spain is madrid, and the capital of portugal is lisbon. while these capitals are in europe, while these capitals are \\nin europe, washington is in the united states. these capitals remain important, these remain important, these places remain important in the world. the \\ncapital of each country is its own, the capital of each country is its identity, the capital of each country is its culture. europe is made of many, \\neurope is made of many capitals, europe is made of many important places. each place is rich with culture, each place is rich with history, and each capital is \\n\\nrich with identity. the world is made of capitals, the world is made of, the world is made of places, and the capital of the united states is washington, \\nnot any european city, not paris, not london, not berlin. the capital of the united states is not london. the capital of france is paris, and berlin is the capital of germany.\\nrome is in italy, madrid is in spain, and lisbon is in portugal. the capital of the united kingdom is not paris, and the capital of the united \\nstates is not berlin. although these places are often mentioned together, each country has its own capital, and each capital has its own identity. \\nwashington is the capital of the united states, and london is the capital of the united kingdom. paris is known for art and fashion, while berlin is \\nfamous for its culture and history. rome is rich with history, and madrid is known for its art and culture. lisbon is a unique city in portugal \\nwith a rich history. these capitals are often mentioned together, although each place with its own culture. the united states is not in europe, \\nand washington is not in any european country. these european capitals are made of history, culture, and identity. each country in europe has a capital, \\nand each capital is known for important. london, paris, berlin, rome, madrid, and lisbon remain important places in the world. while these capitals\\nare in europe, washington is in the united states. although these places are not in the country, they are often mentioned together in art, culture, \\nand history. the capital of each country is its own. europe is made of many capitals, and each has a capital with a unique history. \\nthe world is of important places, and the capital of the united states is washington, not any european city.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"text.txt\", \"r\") as f:\n",
    "  text = f.read()\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = tokenizer.encode(text)\n",
    "# save ids\n",
    "\n",
    "ids_text = \"\"\n",
    "\n",
    "for token_id in token_ids:\n",
    "  ids_text += f\"{token_id} \"\n",
    "\n",
    "with open(\"token_ids.txt\", \"w\") as f:\n",
    "  f.write(ids_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from text_dataset import TextDataset\n",
    "\n",
    "stride = 12\n",
    "\n",
    "def create_data_loader(token_ids: list, context_length: int, stride: int,\n",
    "                       batch_size: int, shuffle: bool = True, device: str = \"cpu\"):\n",
    "  dataset = TextDataset(token_ids, context_length, stride)\n",
    "  dataloader = DataLoader(\n",
    "      dataset,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=shuffle,\n",
    "      generator=torch.Generator(device=device)\n",
    "    )\n",
    "  \n",
    "  return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_loader = create_data_loader(token_ids, context_length, stride, 1, False)\n",
    "\n",
    "len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, [tensor([[ 0, 61,  1, 61,  2, 61,  0, 61,  3, 61,  4, 58]]), tensor([[61,  1, 61,  2, 61,  0, 61,  3, 61,  4, 58, 61]])])\n",
      "(1, [tensor([[61,  5, 61,  6, 61,  7, 59, 61,  0, 61,  1, 61]]), tensor([[ 5, 61,  6, 61,  7, 59, 61,  0, 61,  1, 61,  2]])])\n",
      "(2, [tensor([[ 2, 61,  8, 61,  5, 61,  9, 60, 61, 10, 61, 11]]), tensor([[61,  8, 61,  5, 61,  9, 60, 61, 10, 61, 11, 61]])])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for batch in enumerate(train_data_loader):\n",
    "  print(batch)\n",
    "  i += 1\n",
    "  if i > 2:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
